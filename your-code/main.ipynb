{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "# from pprint import pprint\n",
    "# from lxml import html\n",
    "# from lxml.html import fromstring\n",
    "# import urllib.request\n",
    "from urllib.request import urlopen\n",
    "# import random\n",
    "import re\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "developers = soup.find_all(\n",
    "        name=\"h1\", \n",
    "        class_=\"h3 lh-condensed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "developers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [d.text for d in developers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hackerman', 'PySimpleGUI', 'Dotan Simha', 'Sylvain Gugger', 'Olivier Halligon', 'Magnus Edenhill', 'Barry vd. Heuvel', 'Daniel Lemire', 'Marc Rousavy', 'Jaime Blasco', 'Florian Roth', 'Thijs Schreijer', 'Koen Kanters', 'Simon Willison', 'Yihui Xie', 'Qiusheng Wu', 'Henrik Rydgård', 'Jesse Wilson', 'Benjie Gillam', 'Arda TANRIKULU', 'Álvaro', 'Will McGugan', 'Guilherme Salazar', 'Kyle Conroy', 'Nico Schlömer']\n"
     ]
    }
   ],
   "source": [
    "members = [re.search(\"(\\w+).*\",n)[0] for n in names]\n",
    "print(members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = 'https://github.com/trending/python?since=daily'\n",
    "response = requests.get(url1)\n",
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories = soup.find_all(name=\"h1\", class_=\"h3 lh-condensed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = [r.text for r in repositories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "repositories_list = [re.search(\"(\\w+).*\",n)[1] for n in repo]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "url2 = 'https://en.wikipedia.org/wiki/Walt_Disney'\n",
    "response = requests.get(url2)\n",
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = soup.find_all(name=\"a\", class_=\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "disney_images = [im['href'] for im in images]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "url3 ='https://en.wikipedia.org/wiki/Python' \n",
    "response = requests.get(url3)\n",
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = soup.find_all(name=\"div\", class_=\"mw-body-content mw-content-ltr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = links[0].select('ul')\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = l[3].select('li')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li><a href=\"/wiki/Python_(programming_language)\" title=\"Python (programming language)\">Python (programming language)</a></li>,\n",
       " <li>Python, a native code compiler for <a href=\"/wiki/CMU_Common_Lisp\" title=\"CMU Common Lisp\">CMU Common Lisp</a></li>,\n",
       " <li>Python, the internal project name for the <a href=\"/wiki/PERQ#PERQ_3\" title=\"PERQ\">PERQ 3</a> computer workstation</li>]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = m[0].select('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/wiki/Python_(programming_language)\" title=\"Python (programming language)\">Python (programming language)</a>]"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []\n",
    "for tag in python_links:\n",
    "    link = tag.get('href')\n",
    "    if link is not None:\n",
    "        if link.startswith(\"http\"):\n",
    "            links.append(link)\n",
    "links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "url4 = 'http://uscode.house.gov/download/download.shtml'\n",
    "response = requests.get(url4)\n",
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcodes = soup.find_all(name=\"div\", class_=\"usctitlechanged\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"usctitlechanged\" id=\"us/usc/t31\">\n",
       " \n",
       "           Title 31 - Money and Finance <span class=\"footnote\"><a class=\"fn\" href=\"#fn\">٭</a></span>\n",
       " </div>,\n",
       " <div class=\"usctitlechanged\" id=\"us/usc/t38\">\n",
       " \n",
       "           Title 38 - Veterans' Benefits <span class=\"footnote\"><a class=\"fn\" href=\"#fn\">٭</a></span>\n",
       " </div>]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allcodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "codes = [c.text for c in allcodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n\\n          Title 31 - Money and Finance ٭\\n',\n",
       " \"\\n\\n          Title 38 - Veterans' Benefits ٭\\n\"]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_codes = [re.search(\"(\\w+).*\",h)[0] for h in codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Title 31 - Money and Finance ٭', \"Title 38 - Veterans' Benefits ٭\"]"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ch_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "url5 = 'https://www.emsc-csem.org/Earthquake/'\n",
    "response = requests.get(url5)\n",
    "soup = BeautifulSoup(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthquakes = soup.find_all('tbody')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "earthq = [e.text for e in earthquakes]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'earthquake2021-09-01\\xa0\\xa0\\xa016:19:01.820min ago35.47\\xa0N\\xa0\\xa03.67\\xa0W\\xa0\\xa018ML2.1\\xa0STRAIT OF GIBRALTAR2021-09-01 16:32\\nearthquake2021-09-01\\xa0\\xa0\\xa016:17:38.021min ago8.83\\xa0N\\xa0\\xa0126.38\\xa0E\\xa0\\xa046 M3.2\\xa0MINDANAO, PHILIPPINES2021-09-01 16:25\\nearthquake2021-09-01\\xa0\\xa0\\xa016:07:04.831min ago37.78\\xa0N\\xa0\\xa014.72\\xa0E\\xa0\\xa026ML2.0\\xa0SICILY, ITALY2021-09-01 16:18\\nearthquake2021-09-01\\xa0\\xa0\\xa015:35:41.51hr 03min ago35.40\\xa0N\\xa0\\xa03.66\\xa0W\\xa0\\xa015ML2.2\\xa0STRAIT OF GIBRALTAR2021-09-01 15:50\\nearthquake2021-09-01\\xa0\\xa0\\xa015:26:03.41hr 12min ago35.12\\xa0N\\xa0\\xa095.34\\xa0W\\xa0\\xa07ML3.0\\xa0OKLAHOMA2021-09-01 15:36\\nearthquake2021-09-01\\xa0\\xa0\\xa015:22:26.01hr 16min ago35.40\\xa0N\\xa0\\xa03.64\\xa0W\\xa0\\xa018ML2.0\\xa0STRAIT OF GIBRALTAR2021-09-01 15:28\\nearthquake2021-09-01\\xa0\\xa0\\xa015:20:21.11hr 18min ago35.48\\xa0N\\xa0\\xa03.63\\xa0W\\xa0\\xa018ML2.2\\xa0STRAIT OF GIBRALTAR2021-09-01 15:24\\nearthquake2021-09-01\\xa0\\xa0\\xa015:17:34.01hr 21min ago11.30\\xa0N\\xa0\\xa086.09\\xa0W\\xa0\\xa028 M2.6\\xa0NEAR COAST OF NICARAGUA2021-09-01 15:21\\nearthquake2021-09-01\\xa0\\xa0\\xa015:07:02.61hr 32min ago34.77\\xa0S\\xa0\\xa0178.74\\xa0E\\xa0\\xa0300M 3.6\\xa0SOUTH OF KERMADEC ISLANDS2021-09-01 15:15\\nearthquake2021-09-01\\xa0\\xa0\\xa015:01:18.31hr 37min ago35.71\\xa0N\\xa0\\xa03.90\\xa0W\\xa0\\xa010ML1.9\\xa0STRAIT OF GIBRALTAR2021-09-01 15:20\\nearthquake2021-09-01\\xa0\\xa0\\xa014:54:14.41hr 44min ago35.36\\xa0N\\xa0\\xa03.63\\xa0W\\xa0\\xa021ML2.3\\xa0STRAIT OF GIBRALTAR2021-09-01 15:15\\nearthquake2021-09-01\\xa0\\xa0\\xa014:43:51.31hr 55min ago19.24\\xa0N\\xa0\\xa0155.37\\xa0W\\xa0\\xa031Md2.1\\xa0ISLAND OF HAWAII, HAWAII2021-09-01 14:47\\nearthquake2021-09-01\\xa0\\xa0\\xa014:39:45.31hr 59min ago35.40\\xa0N\\xa0\\xa03.69\\xa0W\\xa0\\xa018ML2.1\\xa0STRAIT OF GIBRALTAR2021-09-01 15:06\\nearthquake2021-09-01\\xa0\\xa0\\xa014:19:56.92hr 19min ago19.23\\xa0N\\xa0\\xa0155.42\\xa0W\\xa0\\xa033Md2.3\\xa0ISLAND OF HAWAII, HAWAII2021-09-01 14:23\\nearthquake2021-09-01\\xa0\\xa0\\xa014:17:12.02hr 21min ago23.95\\xa0S\\xa0\\xa066.88\\xa0W\\xa0\\xa0225 M3.9\\xa0JUJUY, ARGENTINA2021-09-01 14:26\\nearthquake2021-09-01\\xa0\\xa0\\xa014:11:40.32hr 27min ago17.94\\xa0N\\xa0\\xa067.11\\xa0W\\xa0\\xa012Md2.3\\xa0PUERTO RICO REGION2021-09-01 14:46\\nearthquake2021-09-01\\xa0\\xa0\\xa013:50:13.12hr 48min ago1.10\\xa0S\\xa0\\xa024.31\\xa0W\\xa0\\xa010Mw5.7\\xa0CENTRAL MID-ATLANTIC RIDGE2021-09-01 14:36\\nearthquake2021-09-01\\xa0\\xa0\\xa013:46:00.22hr 53min ago19.15\\xa0N\\xa0\\xa0155.46\\xa0W\\xa0\\xa034Md2.0\\xa0ISLAND OF HAWAII, HAWAII2021-09-01 13:49\\nearthquake2021-09-01\\xa0\\xa0\\xa013:40:39.02hr 58min ago0.08\\xa0S\\xa0\\xa0123.93\\xa0E\\xa0\\xa0112 M4.5\\xa0SULAWESI, INDONESIA2021-09-01 13:45\\nearthquake2021-09-01\\xa0\\xa0\\xa013:28:26.93hr 10min ago19.20\\xa0N\\xa0\\xa0155.44\\xa0W\\xa0\\xa034Md2.3\\xa0ISLAND OF HAWAII, HAWAII2021-09-01 13:31\\nearthquake2021-09-01\\xa0\\xa0\\xa013:25:45.03hr 13min ago8.03\\xa0N\\xa0\\xa0127.26\\xa0E\\xa0\\xa045 M3.8\\xa0PHILIPPINE ISLANDS REGION2021-09-01 13:41\\nearthquake2021-09-01\\xa0\\xa0\\xa013:15:30.23hr 23min ago35.40\\xa0N\\xa0\\xa03.64\\xa0W\\xa0\\xa015ML2.2\\xa0STRAIT OF GIBRALTAR2021-09-01 14:58\\nearthquake2021-09-01\\xa0\\xa0\\xa013:14:28.33hr 24min ago36.47\\xa0N\\xa0\\xa0121.05\\xa0W\\xa0\\xa05Md2.2\\xa0CENTRAL CALIFORNIA2021-09-01 13:16\\nearthquake2021-09-01\\xa0\\xa0\\xa013:04:17.33hr 34min ago35.40\\xa0N\\xa0\\xa03.68\\xa0W\\xa0\\xa04ML2.5\\xa0STRAIT OF GIBRALTAR2021-09-01 14:50\\nearthquake2021-09-01\\xa0\\xa0\\xa013:02:03.63hr 36min ago40.92\\xa0N\\xa0\\xa019.82\\xa0E\\xa0\\xa020ML2.0\\xa0ALBANIA2021-09-01 13:13\\nearthquake2021-09-01\\xa0\\xa0\\xa013:00:43.83hr 38min ago33.81\\xa0N\\xa0\\xa0116.08\\xa0W\\xa0\\xa06Ml2.0\\xa0SOUTHERN CALIFORNIA2021-09-01 13:04\\nearthquake2021-09-01\\xa0\\xa0\\xa012:52:52.03hr 46min ago24.36\\xa0S\\xa0\\xa067.27\\xa0W\\xa0\\xa0193 M3.6\\xa0SALTA, ARGENTINA2021-09-01 13:01\\n8IIIearthquake2021-09-01\\xa0\\xa0\\xa012:51:58.23hr 47min ago35.38\\xa0N\\xa0\\xa03.64\\xa0W\\xa0\\xa010ML3.6\\xa0STRAIT OF GIBRALTAR2021-09-01 13:14\\nearthquake2021-09-01\\xa0\\xa0\\xa012:43:57.83hr 55min ago35.41\\xa0N\\xa0\\xa03.59\\xa0W\\xa0\\xa017ML3.0\\xa0STRAIT OF GIBRALTAR2021-09-01 12:59\\nearthquake2021-09-01\\xa0\\xa0\\xa012:31:23.74hr 07min ago36.86\\xa0N\\xa0\\xa03.06\\xa0W\\xa0\\xa016ML1.8\\xa0STRAIT OF GIBRALTAR2021-09-01 12:41\\nearthquake2021-09-01\\xa0\\xa0\\xa012:25:56.54hr 13min ago19.20\\xa0N\\xa0\\xa0155.43\\xa0W\\xa0\\xa033Md2.0\\xa0ISLAND OF HAWAII, HAWAII2021-09-01 12:29\\nearthquake2021-09-01\\xa0\\xa0\\xa012:23:14.94hr 15min ago33.20\\xa0S\\xa0\\xa0179.95\\xa0E\\xa0\\xa0300M 4.3\\xa0SOUTH OF KERMADEC ISLANDS2021-09-01 12:35\\nearthquake2021-09-01\\xa0\\xa0\\xa012:16:46.94hr 22min ago35.37\\xa0N\\xa0\\xa03.72\\xa0W\\xa0\\xa022ML2.1\\xa0STRAIT OF GIBRALTAR2021-09-01 14:26\\nearthquake2021-09-01\\xa0\\xa0\\xa012:10:48.84hr 28min ago35.60\\xa0N\\xa0\\xa03.64\\xa0W\\xa0\\xa010ML3.2\\xa0STRAIT OF GIBRALTAR2021-09-01 13:13\\nearthquake2021-09-01\\xa0\\xa0\\xa012:05:32.64hr 33min ago35.43\\xa0N\\xa0\\xa03.62\\xa0W\\xa0\\xa028ML2.1\\xa0STRAIT OF GIBRALTAR2021-09-01 14:20\\nearthquake2021-09-01\\xa0\\xa0\\xa011:47:00.04hr 52min ago13.02\\xa0N\\xa0\\xa089.27\\xa0W\\xa0\\xa023 M3.7\\xa0OFFSHORE EL SALVADOR2021-09-01 11:56\\nearthquake2021-09-01\\xa0\\xa0\\xa011:37:05.85hr 01min ago38.32\\xa0N\\xa0\\xa042.81\\xa0E\\xa0\\xa07ML2.2\\xa0EASTERN TURKEY2021-09-01 12:27\\nearthquake2021-09-01\\xa0\\xa0\\xa011:35:16.05hr 03min ago24.10\\xa0S\\xa0\\xa067.37\\xa0W\\xa0\\xa0134 M3.0\\xa0SALTA, ARGENTINA2021-09-01 11:46\\nearthquake2021-09-01\\xa0\\xa0\\xa011:25:28.45hr 13min ago41.46\\xa0N\\xa0\\xa019.66\\xa0E\\xa0\\xa018ML2.1\\xa0ALBANIA2021-09-01 11:36\\nearthquake2021-09-01\\xa0\\xa0\\xa011:10:58.55hr 28min ago35.94\\xa0S\\xa0\\xa0178.55\\xa0E\\xa0\\xa0188M 3.3\\xa0OFF E. COAST OF N. ISLAND, N.Z.2021-09-01 11:20\\n1Fearthquake2021-09-01\\xa0\\xa0\\xa011:07:46.05hr 31min ago0.21\\xa0N\\xa0\\xa099.59\\xa0E\\xa0\\xa010 M3.9\\xa0NORTHERN SUMATRA, INDONESIA2021-09-01 11:15\\nearthquake2021-09-01\\xa0\\xa0\\xa011:07:28.15hr 31min ago40.42\\xa0N\\xa0\\xa034.94\\xa0E\\xa0\\xa014ML2.2\\xa0CENTRAL TURKEY2021-09-01 12:34\\nearthquake2021-09-01\\xa0\\xa0\\xa010:54:23.75hr 44min ago36.80\\xa0N\\xa0\\xa07.40\\xa0W\\xa0\\xa029ML2.5\\xa0STRAIT OF GIBRALTAR2021-09-01 11:21\\nearthquake2021-09-01\\xa0\\xa0\\xa010:32:48.16hr 06min ago39.43\\xa0N\\xa0\\xa027.84\\xa0E\\xa0\\xa07ML2.2\\xa0WESTERN TURKEY2021-09-01 11:26\\n40IIIearthquake2021-09-01\\xa0\\xa0\\xa010:32:11.66hr 06min ago45.65\\xa0N\\xa0\\xa026.48\\xa0E\\xa0\\xa0145mb4.4\\xa0ROMANIA2021-09-01 10:48\\nearthquake2021-09-01\\xa0\\xa0\\xa010:24:56.16hr 14min ago38.06\\xa0N\\xa0\\xa00.12\\xa0E\\xa0\\xa04ML2.4\\xa0SPAIN2021-09-01 10:29\\nearthquake2021-09-01\\xa0\\xa0\\xa010:05:04.06hr 33min ago0.68\\xa0N\\xa0\\xa098.53\\xa0E\\xa0\\xa012 M3.6\\xa0NIAS REGION, INDONESIA2021-09-01 10:11\\nearthquake2021-09-01\\xa0\\xa0\\xa010:02:18.56hr 36min ago58.98\\xa0S\\xa0\\xa025.62\\xa0W\\xa0\\xa048mb5.1\\xa0SOUTH SANDWICH ISLANDS REGION2021-09-01 10:50\\n2IIIearthquake2021-09-01\\xa0\\xa0\\xa009:59:47.76hr 39min ago39.43\\xa0N\\xa0\\xa027.83\\xa0E\\xa0\\xa014ML3.1\\xa0WESTERN TURKEY2021-09-01 10:49\\nearthquake2021-09-01\\xa0\\xa0\\xa009:57:41.66hr 41min ago27.72\\xa0N\\xa0\\xa018.23\\xa0W\\xa0\\xa035ML2.4\\xa0CANARY ISLANDS, SPAIN REGION2021-09-01 10:08\\n'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earthq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://hackevents.co/hackathons'\n",
    "url_hack = 'https://hackevents.co/search/anything/anywhere/anytime' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ironcon",
   "language": "python",
   "name": "ironcon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
